\documentclass{standalone}
\usepackage{standalone}

\begin{document}
\subsection{BWA}
BWA has two tools separately for long\cite{BWA_long} and short\cite{BWA_short} reads. One is BWA-SW or Burrows-Wheeler Aligner's Smith-Waterman Alignment which is for aligning long reads and it is an extended version of their main tool Burrows-Wheeler Alignment tool (BWA) which is mainly to align short reads. BWA is also an enhanced version of their previous tool MAQ\cite{mapLi}. But MAQ had some draw backs that it could not handle gapped alignment for the most frequent type of reads called single-end reads. But in case of long reads, inserts and deletes (indels) are frequent. The speed of MAQ is also a big issue when alignment scaled up.

BWA is developed mainly for handling the Illumina/Solexa\cite{dnaB} technology's 30-100 BP reads. It produces 5 crore to 20 crore reads in every run of the machine. To map these reads to human genome was a big challenge. Many hash-table based tools are developed to face this challenge like ZOOM\cite{ZOOM}, MAQ\cite{geneB}, CloudBurst\cite{CloudBurst}, RMAP\cite{RMAP}, SeqMap\cite{SeqMap}, SHRiMP\cite{SHRIMP}. As they have used hash-table, their memory use is moderate, but they could align very few reads considering the whole human genome. All of them are single threaded and hash the read first then search it in the reference\cite{BWA_short}. On the other hand, some tools hash the genome. 

PASS\cite{PASS}, MOM\cite{MOM}, NovoAlign\cite{NovoCraft}, SOAPv1\cite{SOAPv1}, ReSEQ\cite{RESEQ}, ProbeMatch\cite{ProbeMatch} are in this category. They could be multi-threaded, but their main bottleneck is they usually take large memory to build an index, specially for the human genome\cite{BWA_short}. These tools are dependent on the error rate of the data. More error could consume more. Slider\cite{Slider} is another type of software which use merge-sorting which includes read sequences and reference subsequences.

None of the above tools cared about the BWT FM-index\cite{BWT}. But efficiency of the FM-index is suitable for this work. SOAPv2\cite{SOAPv2} and Bowtie \cite{bowtie} inaugurated the process of fulfillment  of the demand. BWA\cite{BWA_short} is a continuation of that process. This last tool made the thing efficient by following the technique of backward search\cite{backward_search} and traversing the prefix trie of the genome in top-down fashion\cite{TopDownFM}. It reduces the memory consumption of the whole comparing to the other tools.
It takes linear time to find the count of a read. There is no relation of the complexity with the number of count. That means whatever the length of the genome, the complexity does not depend on it. So, it could be the reference genome of Human, E.Coli or any other species, all needs same time to search the count, the length of the read. However, BWA allows K edit distance with respect to the query read.

In Suffix Trie, all repeated string follow the same path and to align one should not match it with each piece of repeated string. It is an advantage of using Suffix Trie\cite{BWA_short} and this makes the FM-index based algorithms efficient. As it stated before, BWA is an implementation of inexact matching and also works for paired-end data.
 
Burrows-Wheeler Aligner's Smith-Waterman Alignment (BWA-SW)\cite{BWA_long} is a tool which is developed dedicatedly for long reads tweaking the BWA. This tool works better than BLAT\cite{BLAT} and as accurate as SSAHA 2\cite{SSAHA}. Both are hashing-based software.  There are some other tools which developed for having extra care on local alignment such as FASTA\cite{FASTA}, BLAST\cite{BLAST}, MegaBLAST\cite{MegaBLAST2,MegaBLAST}, PatternHunter\cite{PatternHunter} etc. They also tried to speed up the process of matching against large reference genome. PacBio reads are very large and it would be more larger day by day. In early days of it's testing, it produced longer than 1K bp reads\cite{pacBioReadLength}. There are some other techniques used to tune the tools for long reads like bounding search process\cite{BWA_short}, filtering out bad matches with q-gram filtration\cite{SHRIMP,RazerS}, spanning the entire read\cite{RMAP,ZOOM,SeqMap} and spaced seed templates\cite{PatternHunter}. Cuashaw2\cite{Cushaw2}, GEM\cite{GEM} also performs comparatively well in some cases.

Most of the tools used hash-table based algorithm, but it is not the only option. Between suffix tree of the reference and a query sequence Smith--Waterman-like dynamic programming that could be applied\cite{alterHashTable}. Here, avoiding the repeated alignment, time could be saved. Later in this chapter, another tool name bowtie2\cite{bowtie2} would be described which uses the same approach and some cases it performs better. 
\end{document}